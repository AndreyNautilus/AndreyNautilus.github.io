[{"content":"YAML format is used in many config files, and here are a few tips to make your yaml files look nicer.\nMultiline text values YAML since version 1.1 (2005) support block indicators to control how parser should handle multiline text. See interactive demo.\nExamples:\n\u0026gt;- means \u0026ldquo;treat single newline symbols ('\\n') as spaces (' '), and remove all newlines at the end\u0026rdquo; (useful to put long description in a yaml key).\n# yaml key: \u0026gt;- very long text # python { \u0026#34;key\u0026#34;: \u0026#34;very long text\u0026#34; } | means \u0026ldquo;keep newline symbols ('\\n') as they are\u0026rdquo; (useful when writing multiple commands in a workflow for GitHub Actions ).\n# yaml key: | command1 command2 command3 # python { \u0026#34;key\u0026#34;: \u0026#34;command1\\ncommand2\\ncommand3\\n\u0026#34; } Anchors YAML since version 1.1 (2005) support anchors: a way to annotate a node for future reuse. \u0026amp;anchor at the beginning of a node value declares an anchor, *anchor value is expanded as anchored node. Use YAML online parser for experimenting.\nExamples:\n# original yaml first-key: \u0026amp;config key: value list: - item1 - item2 second-key: *config # parsed yaml first-key: key: value list: - item1 - item2 second-key: key: value list: - item1 - item2 Anchors are useful when we need to repeat certain sections without copy-pasting them.\nAnchor limitations Anchors are expanded as entire node, it\u0026rsquo;s impossible to add/remove/change keys of a dictionary or items in a list.\n# INVALID first-list: \u0026amp;items - item1 - item2 second-list: *items - item3 # can\u0026#39;t add items # INVALID first-list: \u0026amp;mapping key1: value1 key2: value2 second-list: *mapping key3: value3 # can\u0026#39;t add key/values References YAML specs YAML Multiline cheatsheet YAML online parser ","permalink":"https://andreynautilus.github.io/posts/2025-09-06-yaml-anchors-multiline-text/","summary":"\u0026lsquo;\u0026gt;-\u0026rsquo; and \u0026lsquo;|\u0026rsquo; for multiline text; \u0026lsquo;\u0026amp;id\u0026rsquo; and \u0026lsquo;*id\u0026rsquo; for anchors","title":"YAML: anchors and multiline text"},{"content":"Imagine we\u0026rsquo;re developing a C++ library. We need to deliver this library to a client, and the agreement is to deliver it as a shared library for linux. How to do this?\nLet\u0026rsquo;s define the setup and assumptions:\nwe develop on linux system using well-known compiler, like gcc or clang; we use cmake as build system (backed by make or ninja); we know how to build for the target platform (for example the client provides a toolchain); the target platform may be different from the development platform, and the produced library may require an emulator to run. The setup for our example project includes:\nlibfoo is the library we need to deliver; app is our internal developer app that uses libfoo; The code of example project can be found here.\nBuild configuration cmake has a concept of Build Configurations which controls what options are passed to the compiler. There are 4 default configurations - Debug, Release, RelWithDebInfo and MinSizeRel - and CMAKE_BUILD_TYPE variable controls this.\nDebug - for development use only. No optimizations, debug info included. Release - produces the final deliverable binary. Optimized for speed, no debug info included. RelWithDebInfo - same as Release, but includes debug info. Debug info significantly increases the size of the binary, but allows to analyze crash dumps. MinSizeRel - similar to Release, but optimized for size of the binary rather than execution speed. We can consider shipping the library without debug info - Release or MinSizeRel configuration - if we don\u0026rsquo;t expect to receive and analyze crash dumps from the clients. If we do need to investigate crashes, we need debug symbols, but we also need optimizations, so RelWithDebInfo is our only option. But we don\u0026rsquo;t want to ship a library polluted with debug info.\nThe solution is to put debug info in a separate file.\nStrip the binary file command or readelf tool from binutils package can show if a binary contains debug info. Let\u0026rsquo;s build the library in RelWithDebInfo mode:\ncmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -DBUILD_SHARED_LIBS=ON .. cmake --build . # build succeeds and inspect it:\n$ file libfoo.so libfoo.so: ELF 64-bit LSB shared object, ..., with debug_info, not stripped $ readelf --sections libfoo.so | grep debug ... [28] .debug_aranges PROGBITS 0000000000000000 000030b5 [29] .debug_info PROGBITS 0000000000000000 00003145 ... file prints with debug_info, and readelf --sections shows debug sections, which means the library contains debug symbols. If we would use -DCMAKE_BUILD_TYPE=Release, there would be no debug sections in readelf and file wouldn\u0026rsquo;t show with debug_info.\nobjcopy tool from binutils can copy debug info into a separate file:\nobjcopy --only-keep-debug libfoo.so libfoo.so.debug objcopy --strip-debug --add-gnu-debuglink=libfoo.so.debug libfoo.so cmake usually provides CMAKE_OBJCOPY variable that points to objcopy executable. We can use it to add a custom command to our cmake target and extract debug info during the build.\nIf we rebuild the library with LIBFOO_STRIP=ON:\n# `LIBFOO_STRIP` is a custom option in the example project cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -DBUILD_SHARED_LIBS=ON -DLIBFOO_STRIP=ON .. cmake --build . # build succeeds and inspect the produced binary:\n$ file libfoo.so libfoo.so: ELF 64-bit LSB shared object, ..., not stripped $ readelf --sections libfoo.so | grep debug [28] .gnu_debuglink PROGBITS 0000000000000000 000030b8 readelf shows .gnu_debuglink section only which is a link to a file containing debug info (caused by --add-gnu-debuglink option in the example project). file doesn\u0026rsquo;t show with debug_info, but still shows not stripped - this means that our binary still contains additional unneeded info - for example .symtab section. Unneeded sections can be removed if objcopy is invoked with --strip-unneeded parameter instead of --strip-debug.\ncmake --install has --strip option which performs such aggressive stripping during installation. If we use it after the build:\n# `LIBFOO_STRIP` is a custom option in the example project cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -DBUILD_SHARED_LIBS=ON -DLIBFOO_STRIP=ON .. cmake --build . # build succeeds ctest cmake --install . --prefix=../out --strip and inspect the produced and installed binaries, we\u0026rsquo;ll see that the installed binary is finally stripped:\n$ file libfoo.so libfoo.so: ELF 64-bit LSB shared object, ..., not stripped $ file ../out/lib/libfoo.so ../out/lib/libfoo.so: ELF 64-bit LSB shared object, ..., stripped We need to save the file with debug info (libfoo.so.debug) for every shipped binary, then we will be able to analyze crash dumps that customers may send to us.\nVisibility of exported symbols Shared libraries provide functionality via exported dynamic symbols. If we build libfoo as shared in Release mode:\ncmake -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=ON .. cmake --build . # build succeeds ctest # tests run successfully we\u0026rsquo;ll get libfoo.so as our shared library. To list dynamic symbols we can use nm tool from binutils package:\n$ nm --dynamic libfoo.so # or \u0026#34;nm -D\u0026#34; ... w _ITM_registerTMCloneTable U _Unwind_Resume@GCC_3.0 00000000000012c0 T _ZN6libfoo3fooEv 00000000000013d0 T _ZN6libfoo4foo2Ev 0000000000001450 T _ZN6libfoo8internal12foo_internalB5cxx11Ev U _ZNKSt5ctypeIcE13_M_widen_initEv@GLIBCXX_3.4.11 0000000000001440 W _ZNKSt5ctypeIcE8do_widenEc U _ZNSo3putEc@GLIBCXX_3.4 U _ZNSo5flushEv@GLIBCXX_3.4 ... Looking at this list, there are 2 observations that raise questions:\nthis list contains \u0026ldquo;ugly\u0026rdquo; names instead of pretty C++ names. This is called name mangling and compilers do this to C++ symbols to make them unique. We can add --demangle parameter to nm to get pretty symbols back: $ nm --dynamic --demangle libfoo.so # or \u0026#34;nm -DC\u0026#34; ... w _ITM_registerTMCloneTable U _Unwind_Resume@GCC_3.0 00000000000012c0 T libfoo::foo() 00000000000013d0 T libfoo::foo2() 0000000000001450 T libfoo::internal::foo_internal[abi:cxx11]() U std::ctype\u0026lt;char\u0026gt;::_M_widen_init() const@GLIBCXX_3.4.11 0000000000001440 W std::ctype\u0026lt;char\u0026gt;::do_widen(char) const U std::ostream::put(char)@GLIBCXX_3.4 U std::ostream::flush()@GLIBCXX_3.4 ... Another option is c++filt tool from binutils: nm --dynamic libfoo.so | c++filt will give similar output. there are way too many symbols in the list including our internal symbols (libfoo::internal::foo_internal) and symbols from library dependencies (std::ostream::flush()). This happens because by default all statically linked symbols are visible and exported from dynamic libraries. Users of the library can try to use these symbols which is undesirable. We need to limit symbols visibility to keep the public library API clean. Let\u0026rsquo;s inspect nm output in more details. Symbols with address in the first column are \u0026ldquo;real\u0026rdquo; symbols exported from the library. Users that link against our library can use these symbols (call the functions) freely. The second column is the type of the symbol. What\u0026rsquo;s important for now:\nU means \u0026ldquo;undefined symbol\u0026rdquo; - the symbol is required, and must be provided at runtime via dependencies (note @GLIBCXX_3.4 suffix for example). T means global symbol \u0026ldquo;in .text section\u0026rdquo; - exported from the library. t also means a symbol \u0026ldquo;in .text section\u0026rdquo;, but it\u0026rsquo;s local and not exported (nm --dynamic doesn\u0026rsquo;t show them). w/W means \u0026ldquo;weak symbol\u0026rdquo;. When linking the final application, the linker will pick a non-weak symbol over weak symbols, and pick any weak symbol if no non-weak symbols exist. Typically, weak symbols are default constructors/destructors and templates instantiations. They don\u0026rsquo;t violate ODR rule, and the linker will eliminate duplicates. Our goal is to have all symbols forming public API of our library to be exported (in dynamic section), and no other internal symbols should be exported.\nPass \u0026ldquo;version script\u0026rdquo; file to linker Widely used linkers (like GNU ld and gold or LLVM lld) support version script files via --version-script parameter. Version script files can be used to define visibility of symbols. An example of such file to export symbols from libfoo:: namespace only can look like this:\n{ global: _ZN6libfoo*; local: *; }; This file uses mangled symbol names, so we need know them upfront (by running nm for example).\nTo pass a version script file to the linker we need to add -Wl,--version-script=FILENAME linker option (or add this flag to LINK_FLAGS property of the cmake target). Let\u0026rsquo;s build the library and inspect exported symbols:\n# `LIBFOO_USE_VERSION_SCRIPT` is a custom option in the example project cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=ON -DLIBFOO_USE_VERSION_SCRIPT=ON .. cmake --build . ctest nm --dynamic --demangle libfoo.so ... U _Unwind_Resume@GCC_3.0 00000000000012c0 T libfoo::foo() 00000000000013d0 T libfoo::foo2() 0000000000001450 T libfoo::internal::foo_internal[abi:cxx11]() U std::ctype\u0026lt;char\u0026gt;::_M_widen_init() const@GLIBCXX_3.4.11 ... We see that only symbols from libfoo:: namespace(s) are exported. But internal symbols from libfoo::internal:: namespace are also exported, which we want to avoid.\nAnd here comes the problem: it\u0026rsquo;s not possible to refine the filter by adding libfoo::internal::* in the local section:\n{ global: _ZN6libfoo*; local: _ZN6libfoo8internal*; # won\u0026#39;t work :( *; }; If a symbol matches any wild-star pattern in global section, this symbol will not be checked against patterns in local section.\nOne potential way to overcome this limitation is to list all symbols we want to export explicitly, but that\u0026rsquo;s a tedious work. A script to fetch symbols from nm output can be handy, but requires additional effort.\nPros: no code changes required. Configuration lives in a separate file which can be dynamically created or adjusted.\nCons: limitation for visibility of nested namespaces.\nExplicitly annotate exported symbols A better way is to tell linker to hide all symbols by default and explicitly annotate symbols we want to export. Use -fvisibility=hidden linker flag (or set CXX_VISIBILITY_PRESET hidden cmake property) to make all symbols hidden by default.\n__attribute__((visibility(\u0026quot;default\u0026quot;))) annotation (for GCC and clang) marks symbols for exporting. We can define a macro to avoid typing it every time:\n#define PUBLIC_API_FOO __attribute__((visibility(\u0026#34;default\u0026#34;))) PUBLIC_API_FOO void foo(); It\u0026rsquo;s a common practice to annotate symbols in public header files, but these headers are also usually shipped to customers, and customers don\u0026rsquo;t need this annotation in their code. This macro needs to be defined to nothing when used outside of our build system. cmake automatically provides \u0026lt;target\u0026gt;_EXPORTS compiler definition when a library is built as shared, so we can use it:\n#ifdef foo_EXPORTS # define PUBLIC_API_FOO __attribute__((visibility(\u0026#34;default\u0026#34;))) #else # define PUBLIC_API_FOO #endif PUBLIC_API_FOO void foo(); If we now build the library and inspect exported symbols:\n# `LIBFOO_API_VISIBILITY` is a custom option in the example project cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=ON -DLIBFOO_API_VISIBILITY=ON .. cmake --build . ctest nm --dynamic --demangle libfoo.so ... U _Unwind_Resume@GCC_3.0 00000000000012a0 T libfoo::foo() U std::ctype\u0026lt;char\u0026gt;::_M_widen_init() const@GLIBCXX_3.4.11 ... we\u0026rsquo;ll see that only annotated symbols are exported.\nNote: Don\u0026rsquo;t forget to #include public headers that define exported symbols into compilable files (cpp/cxx/cc). If a header file is never included in any translation unit, it\u0026rsquo;s not processed and effectively ignored.\nPros: all exported symbols are explicitly annotated. It\u0026rsquo;s a conscious decision and low risk of mistakes.\nCons:\npublic headers are \u0026ldquo;polluted\u0026rdquo; with PUBLIC_API_FOO macro, which is meaningless for clients; if different clients need to have access to different set of symbols, this approach requires bulky fine-tuning (for example, split API into categories and export different categories for different customers); Exported symbols and testing Hidden symbols are not visible for the users of the library. Tests (unit tests, components test, etc) are also users of the library, they cannot access hidden symbols.\nShared libraries need well-written interface tests to verify the produced binary. The rest of the testing can be performed on a dedicated build that doesn\u0026rsquo;t hide symbols.\nDependencies Shared libraries as any other binaries may have dependencies on other shared libraries. readelf tool can show what dependencies our library has. Let\u0026rsquo;s build libfoo:\ncmake -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=ON .. cmake --build . # build succeeds and inspect the produced library:\n$ readelf --dynamic libfoo.so Tag Type Name/Value 0x0000000000000001 (NEEDED) Shared library: [libstdc++.so.6] 0x0000000000000001 (NEEDED) Shared library: [libgcc_s.so.1] 0x0000000000000001 (NEEDED) Shared library: [libc.so.6] 0x000000000000000e (SONAME) Library soname: [libfoo.so] ... NEEDED records are shared libraries that our library depends on.\nAlternatively we can use ldd tool to print all (including transitive) shared dependencies. ldd is a runtime tool: it actually invokes the dynamic linker to find dependencies, so it might not always work (for example if the library is cross-compiled for another architecture).\n$ ldd libfoo.so linux-vdso.so.1 (0x00007ffc04386000) libstdc++.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007734bbc00000) libgcc_s.so.1 =\u0026gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007734bbe9e000) libc.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007734bb800000) libm.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007734bbb19000) /lib64/ld-linux-x86-64.so.2 (0x00007734bbeca000) If our library depends on another our library, we have to ship this dependency along with the library itself. A better way is statically link dependencies into the final shared library, that will simplify management a lot, but in some cases it\u0026rsquo;s not possible or allowed.\nNote: I\u0026rsquo;m talking about first-party dependencies (dependencies that we as developers produce). System dependencies should not be statically linked or packaged with the deliverables. Third-party dependencies (like openssl) can follow both approaches and they should be handled on case-by-case basis.\nWhen cmake --build produces a library it embeds full paths to dependencies as RUNPATH records:\nreadelf --dynamic ...so ... 0x0000000000000001 (NEEDED) Shared library: [libbar.so] 0x000000000000001d (RUNPATH) Library runpath: [/home/andrey/projects/learning-playground/linux-shared-lib/build/libbar:] ... which allows any executable in the project (tests or apps) to run without additional configuration, but that\u0026rsquo;s not portable. cmake --install strips these records and leaves just NEEDED record for each dependency:\nreadelf --dynamic installed/...so ... 0x0000000000000001 (NEEDED) Shared library: [libbar.so] This moves the responsibility to provide runtime search paths to the final application. The clients application may be shipped along with its dependencies, or can be an application that expects dependencies to be in specific locations within the application bundle (like Android APK for example). In such cases better let the client deal with search paths.\nNote: there\u0026rsquo;s a very good talk \u0026ldquo;C++ Shared Libraries and Where To Find Them\u0026rdquo; that explains RPATH/RUNPATH handling at compile time and runtime.\nABI versioning via SONAME readelf --dynamic shows SONAME record, which contains a value similar to the filename of the shared library. This value will be embedded into the client application as dynamic dependency when the app is linked against our library. Even though the app links against libfoo.so during the build, at runtime the app will look for a file with the name taken from SONAME record of libfoo.so.\nThis mechanism allows updates of libraries without rebuilding client applications. Libraries that use ABI version management are usually shipped with symlinks, for example:\nlibfoo.so -\u0026gt; libfoo.so.1 # symlink libfoo.so.1 -\u0026gt; libfoo.so.1.0.0 # symlink libfoo.so.1.0.0 # actual library file and SONAME record of the library contains libfoo.so.1. When an app is linked against libfoo.so, at runtime this app will look for libfoo.so.1 file (value of SONAME record). This allows users to update libfoo to version 1.0.1 or 1.1.0 and the app will continue to work (as long as the update process updates symlinks: libfoo.so.1 -\u0026gt; libfoo.so.1.1.0). Users can even install multiple major versions of the same library (1.1.0 and 2.0.0) and apps will be able to find the correct dependency at runtime (one app that depends on libfoo.so.1 will pick libfoo.so.1.1.0 while another app that depends on libfoo.so.2 will pick libfoo.so.2.0.0).\nNote: it\u0026rsquo;s the responsibility of the library authors to actually maintain ABI compatibility.\nIn cmake this can be configured via VERSION and SOVERSION properties. Let\u0026rsquo;s build libfoo:\n# `LIBFOO_VERSIONING` is a custom option in the example project cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -DBUILD_SHARED_LIBS=ON -DLIBFOO_VERSIONING=ON .. cmake --build . and inspect the produced files:\n$ ls -la *.so* lrwxrwxrwx 1 user user 11 Sep 2 19:56 libfoo.so -\u0026gt; libfoo.so.1* lrwxrwxrwx 1 user user 15 Sep 2 19:56 libfoo.so.1 -\u0026gt; libfoo.so.1.2.3* -rwxr-xr-x 1 user user 106840 Sep 2 19:56 libfoo.so.1.2.3* $ readelf --dynamic libfoo.so | grep SONAME 0x000000000000000e (SONAME) Library soname: [libfoo.so.1] If an app is linked against libfoo.so, it will depend at runtime on libfoo.so.1:\n$ readelf --dynamic ./app ... 0x0000000000000001 (NEEDED) Shared library: [libfoo.so.1] ... This might be useful if the shared library that we deliver may be updated on-the-fly, and client apps must continue to work. If the client app is used as a single package and library updates can\u0026rsquo;t happen (for example if our library is packaged in an Android APK file), this versioning can be safely ignored.\nUsage When clients want to use our library, they need to link against libfoo.so and add the path to public headers of our library to their include path.\ncmake has a concept of imported targets for this purpose:\nadd_library(foo SHARED IMPORTED) set_target_properties(foo PROPERTIES IMPORTED_LOCATION path/to/libfoo.so IMPORTED_SONAME libfoo.so ) target_include_directories(foo INTERFACE path/to/libfoo/headers) IMPORTED_SONAME property must match SONAME record in libfoo.so. After that foo target can be used as any other target:\ntarget_link_libraries(app PRIVATE foo) Let\u0026rsquo;s build and install libfoo:\ncd libfoo/build cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=ON -DLIBFOO_API_VISIBILITY=ON -DLIBFOO_STRIP=ON .. cmake --build . # build succeeds ctest # tests run and pass - the library is usable cmake --install . --prefix=../out --strip # install libfoo into \u0026#39;libfoo/out\u0026#39; build the app:\ncd app/build # `LIBFOO_BASE_DIR` is a custom option in the example project cmake -DCMAKE_BUILD_TYPE=Release -DLIBFOO_BASE_DIR=../libfoo/out .. cmake --build . ./app # runs and prints output and inspect the executable:\n$ readelf --dynamic app ... 0x0000000000000001 (NEEDED) Shared library: [libfoo.so] 0x000000000000001d (RUNPATH) Library runpath: [/home/andrey/projects/learning-playground/linux-shared-lib/libfoo/out/lib:] ... $ ldd app linux-vdso.so.1 (0x00007ffe6416f000) libfoo.so =\u0026gt; /home/andrey/projects/learning-playground/linux-shared-lib/libfoo/out/lib/libfoo.so (0x0000771d1f915000) ... This is the executable in the cmake build tree, it contains RUNPATH to locate the exact library it was linked with.\nTo make this application portable, it needs to be installed via cmake --install:\ncmake --install . --prefix=../out --strip readelf --dynamic ../out/bin/app ... 0x0000000000000001 (NEEDED) Shared library: [libfoo.so] 0x0000000000000001 (NEEDED) Shared library: [libstdc++.so.6] 0x0000000000000001 (NEEDED) Shared library: [libc.so.6] ... It has no RPATH/RUNPATH records by default. If we try to run the app, it will fail:\n$ ../out/bin/app ../out/bin/app: error while loading shared libraries: libfoo.so: cannot open shared object file: No such file or directory And that\u0026rsquo;s expected, because libfoo.so is not in any standard search path of the system. We need to either explicitly set relative RPATH for the application during the build and put our libraries there, or use LD_LIBRARY_PATH environment variable:\nlinux-shared-lib$ LD_LIBRARY_PATH=libfoo/out/lib/ ./app/out/bin/app Hello world! cmake project for the client application can be configured to also copy shared libraries from dependencies, copy debug info files, and more, but that\u0026rsquo;s out of scope for this page.\nReferences StackOverflow: What are CMAKE_BUILD_TYPE: Debug, Release, RelWithDebInfo and MinSizeRel? Controlling the Exported Symbols of Shared Libraries Stripped binaries (wiki) C++ Shared Libraries and Where To Find Them GNU Wiki: Visibility attribute ","permalink":"https://andreynautilus.github.io/posts/2025-09-02-distributing-linux-so/","summary":"Build the library, strip debug info, manage symbols visibility, etc.","title":"Build linux shared libraries for distribution"},{"content":"In the life of every big git repository there is a moment when a massive, yet simple change is required, for example:\nadoption of a new code style, or enforcing a style over the entire repo; changing of a widely used common practice (like switching from include guards to pragma once in C++ code); a widely used file/function/dependency needs to be renamed; These changes will \u0026ldquo;separate\u0026rdquo; the git history to before and after such massive commit, making the use of git blame quite challenging.\nIgnore specific commits during blame As usual, git has an option to workaround this. We can instruct git to ignore specific commits during blame operation:\ngit blame --ignore-rev 1dc479a9 -- filename We can save full hashes of such commits into a file (let\u0026rsquo;s call it .git-blame-ignore-revs):\n1dc479a9f9876b4c095a1665e1f206ddc76acdc8 # adoption of a new code style ANOTHER_COMMIT_HASH # massive renaming and pass this file to git:\ngit blame --ignore-revs-file .git-blame-ignore-revs -- filename To avoid typing this parameter every time, it\u0026rsquo;s possible to add it to the repo-local config. Then git will pick this file for every git blame operation:\ngit config --local blame.ignoreRevsFile .git-blame-ignore-revs git blame -- filename # will automatically use .git-blame-ignore-revs file Note: if this option is added to the global git configuration - git config --global blame.ignoreRevsFile .git-blame-ignore-revs - git will try to use this file for every repository in the system, and if a repository does not have this file, git will error out:\ngit blame -- filename fatal: could not open object name list: .git-blame-ignore-revs Integrations GitHub and GitLab support .git-blame-ignore-revs file. It must be in the root of the repository and must have exactly this name.\nIt seems that BitBucket doesn\u0026rsquo;t support this.\n","permalink":"https://andreynautilus.github.io/posts/2025-08-23-git-blame-ignore/","summary":"Use .git-blame-ignore-revs file","title":"Keep 'git blame' clean"},{"content":"GitHub Actions allows to define workflow_dispatch workflow trigger:\non: workflow_dispatch: # manual trigger This event allows to manually trigger the workflow via UI, rest API call or CLI. But according to the docs:\nThis event will only trigger a workflow run if the workflow file exists on the default branch\nwhich is quite inconvenient during development of workflows, or when a workflow must be triggered on a side/release/hotfix branch, or when actions in the workflow rely on specific triggers.\nSolution Contrary to what documentation says, it\u0026rsquo;s actually possible to send workflow_dispatch event to a workflow, which does not exist on the default branch.\nPrerequisite: the workflow must run at least once. For example, temporary add a pull_request trigger to the workflow, create a PR and let the workflow to start. After that pull_request trigger can be removed.\nUse CLI to send the event to the side branch:\nexport GITHUB_TOKEN=YOUR_GITHUB_TOKEN gh workflow run manual_workflow.yaml --repo my_org/my_repo --ref side_branch and go to \u0026ldquo;Actions\u0026rdquo; tab of your repo to watch the workflow run.\n","permalink":"https://andreynautilus.github.io/posts/2025-08-19-github-workflow_dispatch-from-branch/","summary":"gh workflow run manual_workflow.yaml \u0026ndash;repo my_org/my_repo \u0026ndash;ref side_branch","title":"Send workflow_dispatch event to not-default branch"},{"content":"Let\u0026rsquo;s assume we have a hex-based grid and we want to fill this grid with random, but naturally looking areas, like biomes or countries. In this post I will explore and visualize some approaches.\nSide note: why hex-based grid? Because it gives smooth naturally-looking areas compared to square or rectangle grids for example.\nFlood fill This is the simplest approach which comes to mind first. The idea is:\ninitialize areas by picking some random points; iterate over areas and expand them to neighboring points (apply flood-fill algorithm); Depending on the order of iteration over areas and how we pick a point to expand, we\u0026rsquo;ll get different results.\nFully random On each step we pick a random area and expand it to random point:\nThis gives nicely looking results, with ripped edges. But due to fully random nature, one area can expand way more than others and produce weirdly-looking protrusions.\nIterate over areas and expand to nearest point This is the opposite approach that reduces randomness:\ncircularly iterate over all areas (to give every area equal chance to grow); expand each area to the point nearest to the initial point; This gives roundish look. But due to heavy restrictions on how to expand the areas, we can get long protrusions which ruin the entire picture. The easiest way to remove them is to re-generate the layout.\nCombined? It seems that combination of iterative and fully random floodfill will give us a good result, but how can we combine them? The expantion of areas should be random to avoid round shapes. Looping over areas is actually the same as picking random area, because random number generator should give roughly equal amount of every index.\nPossible improvements:\nadd weights to areas to tweak RNG; add weights to expansion points; or implement an analyzer of the produced result and re-generate the layout if the quality is too low; \u0026ldquo;Voronoi\u0026rdquo; principle Another approach is to use Voronoi diagrams: every point belongs to the area which initial point is the closest.\nThe generic solution for Voronoi diagrams on a plane is quite complex, but for grids it\u0026rsquo;s quite simple: iterate over all points of the grid, compute distances to all initial points and pick the minimum.\nHere\u0026rsquo;s how it looks with \u0026ldquo;standard\u0026rdquo; approach:\nLooks geometric, definitely not natural. But still may be useful.\nManhattan distance A way to make it look less geometric is to use a different distance function, for example ManHattan distance. This gives way more stylish result:\nDiagonal borders match the hexagon grid nicely.\nInitial points selection Typically, initial points should be defined by underlying logic of the map/grid, but for this post I pick random points.\nOne approach is to take fully random non-overlapping points. This may result in points located close to each other, which may lead to weird generation results: small areas or long protrusions.\nA better approach is to use \u0026ldquo;best candidate\u0026rdquo; algorithm:\nfor each point generate N candidates; select the candidate that maximazes the minimum distance to already generated points; This will give points which are distant from each other.\nReferences Overview of hex grids: orientation, coordinates, etc. I took the idea of ManHattan distance for Voronoi diagram from this article on Habr. ","permalink":"https://andreynautilus.github.io/posts/2025-06-14-areas-on-hex-grid/","summary":"FloodFill and Voronoi exploration","title":"Areas on hexagon grid"},{"content":"Many years ago I saw a code like this and was quite pizzled: Derived::bar overrides Base::bar even though the return types are different.\nclass A { public: virtual void hello() const { std::cout \u0026lt;\u0026lt; \u0026#34;Hello from A\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class B: public A { public: void hello() const override { std::cout \u0026lt;\u0026lt; \u0026#34;Hello from B\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Base { public: virtual A* bar() { return \u0026amp;a; } private: A a; }; class Derived: public Base { public: // return type is different B* bar() override { return \u0026amp;b; } private: B b; }; (see the code on Compiler Explorer)\nWell, according to C++ standard it\u0026rsquo;s absolutely valid and in line with the definition of virtual methods\nIf some member function vf is declared as virtual in a class Base, and some class Derived, which is derived, directly or indirectly, from Base, has a declaration for member function with the same\nname parameter type list (but not the return type) cv-qualifiers ref-qualifiers Then this function in the class Derived is also virtual (whether or not the keyword virtual is used in its declaration) and overrides Base::vf (whether or not the specifier override is used in its declaration). The most interesting part is that the return type doesn\u0026rsquo;t have to be the same.\nCovariant types This trick is called Covariant return types:\nIf the function Derived::f overrides a function Base::f, their return types must either be the same or be covariant. Two types are covariant if they satisfy all of the following requirements:\nboth types are pointers or references (lvalue or rvalue) to classes. Multi-level pointers or references are not allowed. the referenced/pointed-to class in the return type of Base::f() must be an unambiguous and accessible direct or indirect base class of the referenced/pointed-to class of the return type of Derived::f(). the return type of Derived::f() must be equally or less cv-qualified than the return type of Base::f(). In the example above both A* and B* are pointers, A is a base class of B, and A* and B* have the same cv-qualifiers. So, they\u0026rsquo;re coveriant types, and Derived::bar overrides virtual Base::bar method.\nEven more, Base::bar may change the return type to const A*, and everything will continue to work (because B* is less cv-qualified than const A*).\nclass Base { public: virtual const A* bar() { return \u0026amp;a; } private: A a; }; class Derived: public Base { public: // return type is different B* bar() override { return \u0026amp;b; } private: B b; }; Notes I haven\u0026rsquo;t seen this trick in production code since then, so its usefulness is questionable.\nPotentially, it can be used to get the implementation of the interface from the interface itself in places where the implementation class is accessible.\n","permalink":"https://andreynautilus.github.io/posts/2025-05-01-covariant-return-types/","summary":"Return types of methods-overrides may be different","title":"Covariant types in C++ virtual methods"},{"content":"I came across the following piece of C++ code:\nconst std::uint8_t mask = 0x06; std::uint8_t value = foo(); if (mask \u0026amp; ~value) { // do something } and SonarQube scan emitted a warning for this code:\nif (mask \u0026amp; ~value) { ^~~~~~~~~~~~~ Do not apply \u0026#34;\u0026amp;\u0026#34; bitwise operator to a signed operand. But, both mask and value are unsigned, so where does the signed operand come from?\nIntegral promotion C++ language allows implicit conversion of integral types in some cases, this is called Integral promotion:\nprvalues of small integral types (such as char) and unscoped enumeration types may be converted to prvalues of larger integral types (such as int). In particular, arithmetic operators do not accept types smaller than int as arguments, and integral promotions are automatically applied after lvalue-to-rvalue conversion, if applicable. This conversion always preserves the value.\nAnd bitwise NOT - ~ - is an arithmetic operator, so it will involve integral promotion:\nIf the operand passed to a built-in arithmetic operator is integral or unscoped enumeration type, then before any other action (but after lvalue-to-rvalue conversion, if applicable), the operand undergoes integral promotion.\nSo, that\u0026rsquo;s what happens:\nvalue is promoted to int; bitwise ~ operator is applied to value producing int; mask is promoted to int; bitwise \u0026amp; operator is called with two ints; That\u0026rsquo;s where signed operand comes from.\nInterestingly, explicit cast of ~value to std::uint8_t via static_cast\u0026lt;std::uint8_t\u0026gt;(~value) silences the SonarQube warning (but does not remove the promotion).\nCompiler Explorer gives the expected result:\nsizeof(value)=1 sizeof(~value)=4 sizeof(mask \u0026amp; ~value)=4 typeid(~value)=i So, be careful with arithmetic operators when applied to \u0026ldquo;small\u0026rdquo; integer types.\n","permalink":"https://andreynautilus.github.io/posts/2025-04-24-mysterious-signed-operand/","summary":"Integral promotion in action","title":"Mysterious signed operand in a C++ expression"},{"content":"Let\u0026rsquo;s look at a simple C++ program:\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;unordered_set\u0026gt; void print(const std::unordered_set\u0026lt;int\u0026gt;\u0026amp; s) { for (const auto\u0026amp; n : s) { std::cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } std::cout \u0026lt;\u0026lt; std::endl; } int main() { const std::unordered_set\u0026lt;int\u0026gt; s{1, 2, 3, 4, 5}; // construct a set print(s); const std::unordered_set\u0026lt;int\u0026gt; s_1{s}; // copy the set print(s_1); return 0; } What will be the output of this program? Well, it depends on the STL implementation, because it\u0026rsquo;s unspecified by the standard.\n3 different types of behaviour C++ standard defines 3 types of behaviour:\nundefined behaviour: the standard gives no guarantees, anything can happen. The program may behave differently between different runs; even \u0026ldquo;your computer may explode\u0026rdquo;. That\u0026rsquo;s why it is one of the scariest beasts in C++. unspecified behaviour: the standard delegates the guarantees to the implementation. In this case, the behaviour is defined and the program is predictable, but it may differ per implementation. implementation-defined behavior: same as \u0026ldquo;unspecified behaviour\u0026rdquo;, but the implementation must document it. The copy constructor of std::unordered_set doesn\u0026rsquo;t specify the order of elements in the copy (because it\u0026rsquo;s unordered set), so every STL implementation may behave differently. It is unspecified behaviour.\nAssumptions are wrong Let\u0026rsquo;s make an experiment and compile this program with gcc and clang and see the output:\nclang++ -std=c++14 main.cpp -o main \u0026amp;\u0026amp; ./main g++ -std=c++14 main.cpp -o main \u0026amp;\u0026amp; ./main I use GodBolt Compiler Explorer for this. The page shows the output for gcc-14.2 and clang-19.1.0 (latest), and gcc-6.5 and clang-5.0.1 (some old versions). In all cases the output is similar: both lines print(s) and print(s_1) produce the same output.\nThis gives us an assumption that copy constructor simply copies the underlying data structure and preserves the order of elements. But this is wrong.\nMacOS Let\u0026rsquo;s switch to MacOS and XCode. XCode uses a dedicated apple-clang compiler and MacOS SDK provides the STL implementation. Let\u0026rsquo;s compile and run the same program (tested on XCode-15.0.1 with MacOS SDK 14.0 and XCode-15.3 with MacOS SDK 14.4):\nclang++ -std=c++14 main.cpp -o main \u0026amp;\u0026amp; ./main 5 4 3 2 1 1 2 3 4 5 Wow, the order of elements has changed. Looking into STL sources we\u0026rsquo;ll see that copy constructor inserts elements of the original set into the copy:\ntemplate \u0026lt;class _Value, class _Hash, class _Pred, class _Alloc\u0026gt; unordered_set\u0026lt;_Value, _Hash, _Pred, _Alloc\u0026gt;::unordered_set( const unordered_set\u0026amp; __u) : __table_(__u.__table_) { _VSTD::__debug_db_insert_c(this); __table_.__rehash_unique(__u.bucket_count()); insert(__u.begin(), __u.end()); } This might explain the change. Let\u0026rsquo;s extend our program and copy the set a few more times:\nint main() { const std::unordered_set\u0026lt;int\u0026gt; s{1, 2, 3, 4, 5}; // construct a set print(s); const std::unordered_set\u0026lt;int\u0026gt; s_1{s}; // copy the set print(s_1); const std::unordered_set\u0026lt;int\u0026gt; s_2{s_1}; // copy the set print(s_2); const std::unordered_set\u0026lt;int\u0026gt; s_3{s_2}; // copy the set print(s_3); return 0; } Compile and run it:\nclang++ -std=c++14 main.cpp -o main \u0026amp;\u0026amp; ./main 5 4 3 2 1 1 2 3 4 5 5 4 3 2 1 1 2 3 4 5 The order of elements changes every time the set is copied. And that\u0026rsquo;s perfectly valid according to the standard, and this proves that the original assumption was wrong.\nConclusion Never assume an unspecified behaviour, even if everything seems reasonable and some experiments prove the assumption. The assumption itself may be wrong and any change to the setup may break it and thus break the program.\nThe history behind the story There was a collection defined as\nstruct Collection { std::unordered_set\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt; unique_ids; } This collection used deep copy in copy-constructor, so every time the object is copied, the underlying unordered_set is also copied (which caused the vectors to be re-ordered on MacOS). This collection also implemented an iterator interface (as vector iterator), and this object was used to construct a vector from begin and end iterators.\nEverything worked fine until XCode got updated from 15.0.1 to 15.3, which caused MacOS SDK to be updated from 14.0 to 14.4, which updated STL implementation. std::vector constructor started to copy input iterators less times, which caused the Collection object (as iterator) to be copied even (not odd) amount of times, so the unordered_set is copied even amount of times and its elements got re-ordered. That broke the construction of the resulting vector.\nLuckily there was a unittest that started to fail and allowed to debug and find this bug.\n","permalink":"https://andreynautilus.github.io/posts/2024-12-28-unordered-set-xcode/","summary":"Unspecified behaviour may vary between different STL implementations","title":"Unspecified behaviour in std::unordered_set and MacOS SDK"},{"content":"In some setups we want to have a global .gitignore configuration for all repositories for a user:\nrepositories don\u0026rsquo;t have proper .gitignore file; you want to use a tool or IDE that creates temporary files, which are not ignored by the existing .gitignore file; It\u0026rsquo;s possible to configure local gitignore rules via .git/info/exclude file in a repository, but then the configuration has to be copied to all repos. That\u0026rsquo;s not our way.\nSet core.excludesFile in gitconfig Git documentation explains how to configure gitignore rules globally via core.excludesFile config option. This option points to a file with regular gitignore patterns, that will be applied globally. By default this option points to ~/.config/git/ignore file (see the documentation for details).\nSo, we can use ~/.config/git/ignore as global gitignore without any additional configurations.\nBut we can also configure this option explicitly to point to more obvious location, for example:\ngit config --global core.excludesFile \u0026#34;~/.gitignore\u0026#34; which will add the following section to ~/.gitconfig file:\n[core] excludesFile = ~/.gitignore And now we can use the full power of includeIf constructions of git config file to fine grain the gitignore patterns per folder/remote/branch, etc.\n","permalink":"https://andreynautilus.github.io/posts/2024-12-24-gitignore-global/","summary":"git config core.excludesFile defines global gitignore","title":"Global .gitignore"},{"content":"We need to generate a random point in a circle with uniform distribution.\nA naive approach with polar coordinates by picking a random angle and a random distance doesn\u0026rsquo;t give uniform distribution - there are more points close to center and fewer points at the radius. This article has explanation and visualization.\nNaive approach: NNNN points Correct formula: NNNN points Monte-Carlo approach: NNNN points (NNNN attempts) Correct formula for polar coordinates In polar coordinates:\nangle = random(0, 2 * PI) distance = R * sqrt(random(0, 1)) Where R is the radius of the circle. And transformation to Cortesian coordinates:\nx = distance * cos(angle) y = distance * sin(angle) This article and StackOverflow threads give a mathematically correct explanation.\nMonte Carlo (multiple attempts) Another approach is to generate uniformly distributed random points in the bounding box of the circle and pick the first point that is inside the circle.\nWith random() being a uniformly random number, the naive approach for a point in a square:\nx = random() y = random() give uniformly distributed points. And x * x + y * y \u0026lt;= R * R provides an easy test for point being inside the circle.\nObvious drawback - undefined number of attempts, but with uniformly distributed points the average amount of attempt should not be greater than 2 (on average we need 4 / PI attempts).\n","permalink":"https://andreynautilus.github.io/posts/2024-07-29-random-points-in-circle/","summary":"angle = random(); distance = R * sqrt(random())","title":"Random points in circle with uniform distribution"},{"content":"\u0026ldquo;Random\u0026rdquo; points on a plane We need to generate random, evenly distributed points on a plane. Possible use-cases:\nplace objects in a game world (trees in a forest, grass and rocks in a field, etc); generate points for Voronoi diagram (to get areas of similar size); The simplest approach - to use uniformly distributed points with (random(), random()) - doesn\u0026rsquo;t work, because there will be areas with high density of points and areas with no points at all. Such distribution doesn\u0026rsquo;t look natural.\nNNNN points Jittered grid Grids give even distribution, but the picture will not look random. We can add a small displacement to every point and that will give a much better randomized picture.\nNNNN points The max displacement should be slightly less than half of distance between 2 diagonal neibouring points. This will ensure that each point will stay relatively close to the original position, but still shiftted enough to form random picture.\nPros:\npoints are distributed fairy evenly: no major gaps and no major clusters; each point can be referenced by the original grid point (via an index or coordinates); Cons:\nsome points can still be too close to each other (forming small clusters); some points may fall of the canvas due to shift (the shift can be re-generated increasing the risk of clusters) Poisson disk distribution Another solution is Poisson disk sampling (or Poisson disk distribution): points are placed randomly, maintaining the minimum distance and not too far away from each other.\nNNNN points This article compares randomly placed points with Poisson disk distribution, and shows \u0026ldquo;best candidate\u0026rdquo; and Bridson’s algorithms to build such distribution (with great examples and visualizations).\nBridson’s algorithm for Poisson disk sampling Summary of this page. Bridson\u0026rsquo;s algorithm allows us to generate random points with Poisson disk distribution.\nFormal problem description: generate tightly packed random points maintaining minimal distance between them.\nAlgorithm parameters:\narea where points should be generated; r - minimum distance between any 2 points; k - amount of attempts to generate a new point; The algorithm uses a grid with r/sqrt(2) cell size. There could be at most 1 point in any grid cell. The value of a cell is either an index of a generated point or -1.\nThe algorithm:\ninitialize the grid that covers the requested area with -1 in each cell; generate an initial point p0 and set the corresponding grid cell to 0 (the first point); initialize a list of active points with index 0; pick a random index from active points (let\u0026rsquo;s say p-i). Generate up to k random points in annulus between r and 2r form the selected point p-i; test every generated point if it\u0026rsquo;s far enough (dist \u0026gt;=r) from already existing points (use the grid to test only nearby cells); if a generated point is far enough from all existing points, add it to the list of generated points, update the grid cell with its index and add this new point to active points; if all k points are too close to already existing points, then remove p-i from active points; repeat until list of active points is empty; Side notes:\ncomplexity is O(N); easy to implement; the cluster of points grows naturally from the starting point to all directions; easily extensible to 3D (and more dimensional) space; the number of points is not known until the generation process is complete (it\u0026rsquo;s \u0026ldquo;generate some points with specific condition\u0026rdquo; rather than \u0026ldquo;generate N points\u0026rdquo;); Other options There are other ways to generate evenly distributed random points (see this blog post):\nuse noise; Lloyd\u0026rsquo;s relaxation: apply a few iterations of Lloyd algorithm to move points away from each other; Links https://www.redblobgames.com/x/1830-jittered-grid/ https://www.jasondavies.com/poisson-disc/ ","permalink":"https://andreynautilus.github.io/posts/2024-07-21-evenly-random-points-on-plane/","summary":"Bridson’s Algorithm to build Poisson disk distribution of points","title":"Evenly distributed random points"},{"content":"Linux has multiple values that represent the amount of memory associated with a process:\nRSS or Resident Set Size or RES - total amount of physical memory associated with the process including all shared libraries. PSS or Proportional Set Size - similar to RSS, but shared libraries are counted proportionally: if a library is loaded by multiple (let\u0026rsquo;s say 5) processes, associated memory will be distributed proporiaonally between them (each process will get 1/5 of the library memory). Sum of PSS values of all processes shows total system usage. USS or Unique Set Size - memory unique to the process. When the process is killed, this amount will be returned to the system. VSS or Virtual Set Size or VSZ - total accessible address space of a process including swapped memory and allocated, but not yet used. Examples top command shows VSS (as VIRT) and RSS (as RES):\nPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 650 andrey 20 0 2892 932 840 S 0.0 0.0 0:00.00 sh ps -ux shows VSS (as VSZ) and RSS:\nUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND andrey 650 0.0 0.0 2892 932 pts/0 S+ Jul20 0:00 sh Links For more details see:\nhttps://stackoverflow.com/questions/22372960/is-this-explanation-about-vss-rss-pss-uss-accurate https://2net.co.uk/tutorial/procrank ","permalink":"https://andreynautilus.github.io/posts/2024-07-16-linux-process-memory/","summary":"RSS, VSZ, PSS, USS explained","title":"Linux process memory: RSS, VSZ, etc"},{"content":"Summary of \u0026ldquo;My 3 Rules for Documenting Code\u0026rdquo; article.\nNames (classes, variables, functions) should explain What (what is it? what does this function do?). Code should explain How (how is it implemented?). Comments should explain Why (why is it implemented this way?). Added to the Collection of links.\n","permalink":"https://andreynautilus.github.io/posts/2024-05-26-documenting-code/","summary":"names = what, code = how, comments = why","title":"Documenting code"},{"content":"Multiple users Quite often we need to have multiple git users on the same workstation. For example:\na user for working account; a user for personal account; These users should have different name and email, and might need different configuration and authentication. Accounts for the users can be on different platforms (GitHub, GitLab, BitBucket etc) or on the same.\nA simple solution would be to use repository-local (git config --local) configuration, but this means repeating it over and over again for every cloned repository. This is not an engineers way.\nConfigure git per directory Git stores global configuration in ~/.gitconfig file. It\u0026rsquo;s a text file which supports conditional includes via includeIf directive. We\u0026rsquo;re interested in gitdir condition, which includes the file if the current repository (.git folder of the current repository) is in the specified directory.\nSo, we can nicely isolate all work-related repositories in ~/work directory and all personal repositories in ~/personal directory. For example, the main ~/.gitconfig file may look like:\n[user] name = Alex Green email = alex.green@company.com [includeIf \u0026#34;gitdir:~/work/\u0026#34;] path = ~/.gitconfig-work [includeIf \u0026#34;gitdir:~/personal/\u0026#34;] path = ~/.gitconfig-personal while ~/.gitconfig-work enables commit signing for work account:\n[user] signingkey = XXXXXXX [gpg] program = gpg [commit] gpgsign = true and ~/.gitconfig-personal redefines user name and email for personal account:\n[user] name = Mr Green email = mr-green@personal.com See:\n~/work/company-project $ git config --get user.name Alex Green ~/personal/awesome-project $ git config --get user.name Mr Green ssh authentication Most git platforms (GitHub, GitLab, BitBucket etc) support ssh authentication, and we can configure it in ~/.ssh/config file of our ssh client:\nHost github.com IdentityFile ~/.ssh/github Host bitbucket.com IdentityFile ~/.ssh/bitbucket Then both\ngit clone git@github.com:organization/repository.git git clone git@bitbucket.org:organization/repository.git work and use corresponding ssh keys.\nssh authnetication for the same host But what if we have multiple accounts on the same platform (both accounts are on GitHub for example)? Well, ssh client doesn\u0026rsquo;t know which key to use, so we need to tell it via different host. We can configure the ssh client with artificial host for one of the accounts (for example for personal account):\nHost github.com-personal IdentityFile ~/.ssh/github-personal Host github.com IdentityFile ~/.ssh/github-work Then git clone git@github.com:organization/repository.git will use ~/.ssh/github-work key.\nBut in order to clone a repository using personal ~/.ssh/github-personal key, we need to change the host in url manually (note github.com-personal instead of github.com):\ngit clone git@github.com-personal:organization/repository.git This means we can\u0026rsquo;t use the \u0026ldquo;default\u0026rdquo; clone command provided by the platform, we need to manually adjust it.\nHint: it\u0026rsquo;s generally more convenient to have the \u0026ldquo;default\u0026rdquo; configuration for the account which is used to clone repositories more often, because we can use the \u0026ldquo;default\u0026rdquo; clone command from the platform.\nSome references:\nhttps://stackoverflow.com/questions/67593657/setting-up-multiple-ssh-key-access-to-github https://gist.github.com/alejandro-martin/aabe88cf15871121e076f66b65306610 using core.sshCommand config option (or GIT_SSH_COMMAND environment variable) it\u0026rsquo;s possible to distinguish ssh keys based on current folder; Commit signing Some platforms may require commit signing. I use gpg key for that. GitHub documentation explains how to set it up. We can also configure git to sign our commits by default:\n[user] signingkey = XXXXXXX [gpg] program = gpg [commit] gpgsign = true ","permalink":"https://andreynautilus.github.io/posts/2024-05-22-git-multiple-users/","summary":"Configure multiple git users on the same workstation","title":"git with multiple users"},{"content":"Why do we need to force-push? Force-pushing is not always a bad thing. Sometimes we actually want to re-write the git history. This can be useful if:\nwe want to update a commit message of a previous commit (git commit --amend); we want to squash-merge dozens of small commits before presenting the code to the review (git rebase autosquash -i). When combined with fixup commits this allows to group changes in well-described commits; we want to remove sensitive information (like leaked credential) from the repository; we rebase our branch (on top of the updated main for example); In all these cases we actually want to re-write the git history, so we need to use force-push.\nA safer force-push But git push --force is a dangerous, unconditional override of the history on remote.\nIn git we usually have a branch per feature. This branch is usually maintained by a single developer from the creation till merge, and usually force-pushing to this branch is a relatively safe operation with low risk of overriding someones work. Still sometimes other authors (developers or automation) may push to your feature branch and we don\u0026rsquo;t want to lose these changes.\nTo completely avoid the risk, we should use git push --force-with-lease instead of git push --force. --force-with-lease will block the operation if the remote branch has changes that are not in your local copy. Official documentation has a bit more detailed explanation, but in simple words:\n--force-with-lease will not allow you to override someones changes that were not pulled to your local copy.\nAs a rule of thumb: always use --force-with-lease unless you have very good reasons to use --force.\nDanger zone If after re-writing your local history, but before pushing the changes to remote, you update your local remote-tracking branches (with git fetch for example), --force-with-lease will not save you from overriding others changes. In this case git assumes that\u0026rsquo;s your intention to override someones changes.\nExample Let\u0026rsquo;s simulate this scenario locally, I\u0026rsquo;ll use fixup commits as example. git can use a local repository as remote (I\u0026rsquo;ll use bare repository for this). We\u0026rsquo;re interested in commits, not the actual changes, so all commits will be empty (done with --allow-empty flag).\nInitial setup First, let\u0026rsquo;s create a remote (a bare git repository):\n$ mkdir remote $ cd remote remote $ git init --bare Mr.Green clones the repository, configures the user, initializes the main branch with an empty commit and pushes it to the remote:\n$ mkdir green $ git clone remote green $ cd green green $ git config --local user.name \u0026#34;Alex Green\u0026#34; green $ git config --local user.email \u0026#34;alex.green@address.com\u0026#34; green $ git commit -m \u0026#34;initial commit\u0026#34; --allow-empty green $ git push origin main Next, his co-worker, Mr.Red clones the repository and configures his user:\n$ mkdir red $ git clone remote red $ cd red red $ git config --local user.name \u0026#34;Bob Red\u0026#34; red $ git config --local user.email \u0026#34;bob.red@address.com\u0026#34; Now we have 2 clones from different people of the same remote.\nCreating a conflict Mr.Red creates a branch, makes a few changes and pushes the branch to the remote:\nred $ git checkout -b feature_branch red $ git commit -m \u0026#34;change from Red 1\u0026#34; --allow-empty red $ git commit --fixup HEAD --allow-empty red $ git push --set-upstream origin feature_branch Mr.Red invites his co-worker - Mr.Green - to help. Mr.Green checks out feature_branch, makes some changes and pushes the branch back to remote:\ngreen $ git pull green $ git checkout feature_branch green $ git commit -m \u0026#34;change from Green 1\u0026#34; --allow-empty green $ git push origin feature_branch In the meanwhile, Mr.Red continues to make changes. When ready, he squashes the changes to produce a \u0026ldquo;clean\u0026rdquo; history for the review process:\nred $ git commit --fixup HEAD~1 --allow-empty red $ git rebase --autosquash --interactive HEAD~3 # accept all changes Boom! Now the git history in Mr.Reds local copy has a conflict with the remote (what Mr.Green pushed):\nred $ git log --oneline feature_branch 266b934 (HEAD -\u0026gt; feature_branch) change from Red 1 71737b9 (origin/main, origin/HEAD, main) initial commit green $ git log --oneline feature_branch fa25da6 (HEAD -\u0026gt; feature_branch, origin/feature_branch) change from Green 1 c905bcf fixup! change from Red 1 863c570 change from Red 1 71737b9 (origin/main, main) initial commit (note the commit hashes!)\nHandling the conflict Mr.Red re-wrote the history of his branch, and if he tries to git push, the operation will fail. Mr.Red knows that he needs to force-push in order to send his branch to the remote.\nMr.Red might not be aware of the changes from Mr.Green, so using git push --force will override the commit from Mr.Green. --force-with-lease prevents it:\nred $ git push origin feature_branch --force-with-lease To C:/Projects/git_push_force_example/remote ! [rejected] feature_branch -\u0026gt; feature_branch (stale info) error: failed to push some refs to \u0026#39;C:/Projects/git_push_force_example/remote\u0026#39; Voila! Mr.Red didn\u0026rsquo;t override someones commit and needs to rebase and re-apply his changes.\nDanger zone If Mr.Red updates his local remote-tracking branches (with git fetch):\nred $ git log --oneline origin/feature_branch c905bcf (origin/feature_branch) fixup! change from Red 1 863c570 change from Red 1 71737b9 (origin/main, origin/HEAD, main) initial commit red $ git fetch red $ git log --oneline origin/feature_branch fa25da6 (origin/feature_branch) change from Green 1 c905bcf fixup! change from Red 1 863c570 change from Red 1 71737b9 (origin/main, origin/HEAD, main) initial commit the push operation will succeed and it will override the commit from Mr.Green on the remote. This happens, because git fetch brings the commit from Mr.Green to the local copy of Mr.Red, and git assumes that Mr.Red actually wants to override the commit from Mr.Green.\nConclusion Always prefer git push --force-with-lease over git push --force and use git fetch consciously.\n","permalink":"https://andreynautilus.github.io/posts/2024-05-16-git-force-vs-force-with-lease/","summary":"Prefer \u0026lsquo;git push \u0026ndash;force-with-lease\u0026rsquo; over \u0026lsquo;git push \u0026ndash;force\u0026rsquo;","title":"git push --force vs --force-with-lease"},{"content":"Tools https://regex101.com/ - online RegEx tester/debugger https://crontab.guru/ - cron explainer https://github.com/refined-github/refined-github - browser extension to greatly enrich GitHub UI https://ohshitgit.com/ - git cheatsheet for \u0026ldquo;shit happened\u0026rdquo; cases Bash scripting docs: conditions and vars expansion YAML online parser and multiline strings - (post) Procedural generation https://www.boristhebrave.com/ : Diablo 1 dungeon generation, unExplored dungeon generation, etc. https://www.redblobgames.com/ : map generation from noise and from polygons, random polyline between 2 points and lots of useful links. Overview of Maze generation algorithms Poisson disk sampling and Bridson’s algorithm - (post) Random point in a circle with uniform distribution - (post) Layer-Based Procedural Generation for Infinite Star Systems A simple procedural animation technique - animating a snake/lizzard -like creature. Dungeon generation (more advanced random room placement) Wave function collapse algorithm Noise-based terrain generation techniques Other \u0026ldquo;My 3 Rules for Documenting Code\u0026rdquo; article (post) Linux process memory: RSS, PSS, USS explained (post) Soma on dev.to - collection of 101 articles about System Design SQL Murder Mystery - gamified SQL exercise. Use SQL queries to relate the clues and solve the puzzle. C++ Shared Libraries and Where To Find Them - a talk from CppCon 2024 that structures how to build and load shared libraries on linux/macos/windows. ","permalink":"https://andreynautilus.github.io/links/","summary":"\u003ch2 id=\"tools\"\u003eTools\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://regex101.com/\"\u003ehttps://regex101.com/\u003c/a\u003e - online RegEx tester/debugger\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://crontab.guru/\"\u003ehttps://crontab.guru/\u003c/a\u003e - cron explainer\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/refined-github/refined-github\"\u003ehttps://github.com/refined-github/refined-github\u003c/a\u003e - browser extension to greatly enrich GitHub UI\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ohshitgit.com/\"\u003ehttps://ohshitgit.com/\u003c/a\u003e - git cheatsheet for \u0026ldquo;shit happened\u0026rdquo; cases\u003c/li\u003e\n\u003cli\u003eBash scripting docs: \u003ca href=\"https://www.gnu.org/software/bash/manual/bash.html#Bash-Conditional-Expressions\"\u003econditions\u003c/a\u003e and\n\u003ca href=\"https://www.gnu.org/software/bash/manual/bash.html#Shell-Parameter-Expansion-1\"\u003evars expansion\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eYAML \u003ca href=\"https://yaml-online-parser.appspot.com/\"\u003eonline parser\u003c/a\u003e and \u003ca href=\"https://yaml-multiline.info/\"\u003emultiline strings\u003c/a\u003e - (\u003ca href=\"../posts/2025-09-06-yaml-anchors-multiline-text\"\u003epost\u003c/a\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"procedural-generation\"\u003eProcedural generation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.boristhebrave.com/\"\u003ehttps://www.boristhebrave.com/\u003c/a\u003e :\n\u003ca href=\"https://www.boristhebrave.com/2019/07/14/dungeon-generation-in-diablo-1/\"\u003eDiablo 1 dungeon generation\u003c/a\u003e,\n\u003ca href=\"https://www.boristhebrave.com/2021/04/10/dungeon-generation-in-unexplored/\"\u003eunExplored dungeon generation\u003c/a\u003e,\netc.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.redblobgames.com/\"\u003ehttps://www.redblobgames.com/\u003c/a\u003e :\n\u003ca href=\"https://www.redblobgames.com/maps/terrain-from-noise/\"\u003emap generation from noise\u003c/a\u003e and\n\u003ca href=\"http://www-cs-students.stanford.edu/~amitp/game-programming/polygon-map-generation/\"\u003efrom polygons\u003c/a\u003e,\n\u003ca href=\"https://www.redblobgames.com/maps/noisy-edges/\"\u003erandom polyline between 2 points\u003c/a\u003e and\nlots of useful links.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://professor-l.github.io/mazes/\"\u003eOverview of Maze generation algorithms\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://bost.ocks.org/mike/algorithms/\"\u003ePoisson disk sampling\u003c/a\u003e and \u003ca href=\"https://sighack.com/post/poisson-disk-sampling-bridsons-algorithm\"\u003eBridson’s algorithm\u003c/a\u003e - (\u003ca href=\"../posts/2024-07-21-evenly-random-points-on-plane\"\u003epost\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.anderswallin.net/2009/05/uniform-random-points-in-a-circle-using-polar-coordinates/\"\u003eRandom point in a circle with uniform distribution\u003c/a\u003e - (\u003ca href=\"../posts/2024-07-29-random-points-in-circle\"\u003epost\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\n  \n  \u003cspan class=\"inline-icon\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n    stroke-linecap=\"round\" stroke-linejoin=\"round\"\u003e\n    \u003cpath\n        d=\"M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z\"\u003e\n    \u003c/path\u003e\n    \u003cpolygon points=\"9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02\"\u003e\u003c/polygon\u003e\n\u003c/svg\u003e\n  \u003c/span\u003e\n\u003ca href=\"https://www.youtube.com/watch?v=GJWuVwZO98s\"\u003eLayer-Based Procedural Generation for Infinite Star Systems\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n  \n  \u003cspan class=\"inline-icon\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n    stroke-linecap=\"round\" stroke-linejoin=\"round\"\u003e\n    \u003cpath\n        d=\"M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z\"\u003e\n    \u003c/path\u003e\n    \u003cpolygon points=\"9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02\"\u003e\u003c/polygon\u003e\n\u003c/svg\u003e\n  \u003c/span\u003e\n\u003ca href=\"https://www.youtube.com/watch?v=qlfh_rv6khY\"\u003eA simple procedural animation technique\u003c/a\u003e -\nanimating a snake/lizzard -like creature.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.gamedeveloper.com/programming/procedural-dungeon-generation-algorithm\"\u003eDungeon generation (more advanced random room placement)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\n  \n  \u003cspan class=\"inline-icon\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n    stroke-linecap=\"round\" stroke-linejoin=\"round\"\u003e\n    \u003cpath\n        d=\"M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22\"\u003e\n    \u003c/path\u003e\n\u003c/svg\u003e\n  \u003c/span\u003e\n\u003ca href=\"https://github.com/mxgmn/WaveFunctionCollapse\"\u003eWave function collapse\u003c/a\u003e algorithm\u003c/li\u003e\n\u003cli\u003e\n  \n  \u003cspan class=\"inline-icon\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n    stroke-linecap=\"round\" stroke-linejoin=\"round\"\u003e\n    \u003cpath\n        d=\"M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z\"\u003e\n    \u003c/path\u003e\n    \u003cpolygon points=\"9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02\"\u003e\u003c/polygon\u003e\n\u003c/svg\u003e\n  \u003c/span\u003e\n\u003ca href=\"https://www.youtube.com/watch?v=QF2Nj1zME40\"\u003eNoise-based terrain generation techniques\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"other\"\u003eOther\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://dev.to/wraith/my-3-rules-for-documenting-code-2f54\"\u003e\u0026ldquo;My 3 Rules for Documenting Code\u0026rdquo; article\u003c/a\u003e\n(\u003ca href=\"../posts/2024-05-26-documenting-code\"\u003epost\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://stackoverflow.com/questions/22372960/is-this-explanation-about-vss-rss-pss-uss-accurate\"\u003eLinux process memory: RSS, PSS, USS explained\u003c/a\u003e (\u003ca href=\"../posts/2024-07-16-linux-process-memory\"\u003epost\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://dev.to/somadevtoo\"\u003eSoma on dev.to\u003c/a\u003e - collection of 101 articles about System Design\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://mystery.knightlab.com/\"\u003eSQL Murder Mystery\u003c/a\u003e - gamified SQL exercise. Use SQL queries to relate the clues and solve the puzzle.\u003c/li\u003e\n\u003cli\u003e\n  \n  \u003cspan class=\"inline-icon\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"\n    stroke-linecap=\"round\" stroke-linejoin=\"round\"\u003e\n    \u003cpath\n        d=\"M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z\"\u003e\n    \u003c/path\u003e\n    \u003cpolygon points=\"9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02\"\u003e\u003c/polygon\u003e\n\u003c/svg\u003e\n  \u003c/span\u003e\n\u003ca href=\"https://www.youtube.com/watch?v=Ik3gR65oVsM\"\u003eC++ Shared Libraries and Where To Find Them\u003c/a\u003e - a talk from CppCon 2024\nthat structures how to build and load shared libraries on linux/macos/windows.\u003c/li\u003e\n\u003c/ul\u003e","title":"Collection of useful links"}]